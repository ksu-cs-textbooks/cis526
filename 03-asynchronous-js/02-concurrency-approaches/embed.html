<!doctype html><html lang=en-us dir=ltr itemscope itemtype=http://schema.org/Article><head><meta charset=utf-8><meta name=viewport content="height=device-height,width=device-width,initial-scale=1,minimum-scale=1"><meta name=generator content="Hugo 0.128.0"><meta name=generator content="Relearn 6.0.0"><meta name=description content="Concurrency means “doing more than one thing at the same time.” In computer science, concurrency can refer to (1) structuring a program or algorithm so that it can be executed out-of-order or in partial order, or (2) actually executing computations in parallel. In modern-day programming, we’re often talking about both. But to help us develop a stronger understanding, let’s look at the two ideas one-at-a-time, and then bring it together."><meta name=author content="Nathan Bean"><meta name=twitter:card content="summary"><meta name=twitter:title content="Concurrency Approaches :: CIS 526 Textbook"><meta name=twitter:description content="Concurrency means “doing more than one thing at the same time.” In computer science, concurrency can refer to (1) structuring a program or algorithm so that it can be executed out-of-order or in partial order, or (2) actually executing computations in parallel. In modern-day programming, we’re often talking about both. But to help us develop a stronger understanding, let’s look at the two ideas one-at-a-time, and then bring it together."><meta property="og:url" content="https://textbooks.cs.ksu.edu/cis526/03-asynchronous-js/02-concurrency-approaches/embed.html"><meta property="og:site_name" content="CIS 526 Textbook"><meta property="og:title" content="Concurrency Approaches :: CIS 526 Textbook"><meta property="og:description" content="Concurrency means “doing more than one thing at the same time.” In computer science, concurrency can refer to (1) structuring a program or algorithm so that it can be executed out-of-order or in partial order, or (2) actually executing computations in parallel. In modern-day programming, we’re often talking about both. But to help us develop a stronger understanding, let’s look at the two ideas one-at-a-time, and then bring it together."><meta property="og:locale" content="en-us"><meta property="og:type" content="article"><meta property="article:section" content="Asynchronous JavaScript"><meta property="article:published_time" content="2018-08-24T10:53:26-05:00"><meta property="article:modified_time" content="2025-02-12T13:30:49-06:00"><meta itemprop=name content="Concurrency Approaches :: CIS 526 Textbook"><meta itemprop=description content="Concurrency means “doing more than one thing at the same time.” In computer science, concurrency can refer to (1) structuring a program or algorithm so that it can be executed out-of-order or in partial order, or (2) actually executing computations in parallel. In modern-day programming, we’re often talking about both. But to help us develop a stronger understanding, let’s look at the two ideas one-at-a-time, and then bring it together."><meta itemprop=datePublished content="2018-08-24T10:53:26-05:00"><meta itemprop=dateModified content="2025-02-12T13:30:49-06:00"><meta itemprop=wordCount content="1223"><title>Concurrency Approaches :: CIS 526 Textbook</title>
<link href=https://textbooks.cs.ksu.edu/cis526/03-asynchronous-js/02-concurrency-approaches/ rel=canonical type=text/html title="Concurrency Approaches :: CIS 526 Textbook"><link href=/cis526/03-asynchronous-js/02-concurrency-approaches/index.xml rel=alternate type=application/rss+xml title="Concurrency Approaches :: CIS 526 Textbook"><link href=/cis526/03-asynchronous-js/02-concurrency-approaches/index.print.html rel=alternate type=text/html title="Concurrency Approaches :: CIS 526 Textbook"><link href=/cis526/03-asynchronous-js/02-concurrency-approaches/tele.html rel=alternate type=text/html title="Concurrency Approaches :: CIS 526 Textbook"><link href=/cis526/css/fontawesome-all.min.css?1739827139 rel=stylesheet media=print onload='this.media="all",this.onload=null'><noscript><link href=/cis526/css/fontawesome-all.min.css?1739827139 rel=stylesheet></noscript><link href=/cis526/css/nucleus.css?1739827139 rel=stylesheet><link href=/cis526/css/auto-complete.css?1739827139 rel=stylesheet media=print onload='this.media="all",this.onload=null'><noscript><link href=/cis526/css/auto-complete.css?1739827139 rel=stylesheet></noscript><link href=/cis526/css/perfect-scrollbar.min.css?1739827139 rel=stylesheet><link href=/cis526/css/fonts.css?1739827139 rel=stylesheet media=print onload='this.media="all",this.onload=null'><noscript><link href=/cis526/css/fonts.css?1739827139 rel=stylesheet></noscript><link href=/cis526/css/theme.css?1739827139 rel=stylesheet><link href=/cis526/css/theme-light-theme.css?1739827139 rel=stylesheet id=R-variant-style><link href=/cis526/css/chroma-relearn-light.css?1739827139 rel=stylesheet id=R-variant-chroma-style><link href=/cis526/css/variant.css?1739827139 rel=stylesheet><link href=/cis526/css/print.css?1739827139 rel=stylesheet media=print><script>window.relearn=window.relearn||{},window.relearn.relBasePath="../..",window.relearn.relBaseUri="../../..",window.relearn.absBaseUri="https://textbooks.cs.ksu.edu/cis526",window.index_js_url="/cis526/index.search.js",window.variants&&variants.init(["light-theme"]),window.T_Copy_to_clipboard=`Copy to clipboard`,window.T_Copied_to_clipboard=`Copied to clipboard!`,window.T_Copy_link_to_clipboard=`Copy link to clipboard`,window.T_Link_copied_to_clipboard=`Copied link to clipboard!`,window.T_Reset_view=`Reset view`,window.T_View_reset=`View reset!`,window.T_No_results_found=`No results found for "{0}"`,window.T_N_results_found=`{1} results found for "{0}"`</script><link href=/cis526/css/custom.css?1739827139 rel=stylesheet></head><body class="mobile-support embed disableInlineCopyToClipboard" data-url=/cis526/03-asynchronous-js/02-concurrency-approaches/embed.html><div id=R-body class=default-animation><div id=R-body-overlay></div><div id=R-main-overlay></div><main id=R-body-inner class="highlightable default" tabindex=-1><div class=flex-block-wrapper><article class=default><p>Concurrency means &ldquo;doing more than one thing at the same time.&rdquo; In computer science, concurrency can refer to (<a href=https://en.wikipedia.org/wiki/Concurrency_(computer_science) rel=external target=_blank>1</a>) structuring a program or algorithm so that it can be executed out-of-order or in partial order, or (<a href=https://en.wikipedia.org/wiki/Concurrent_computing rel=external target=_blank>2</a>) actually executing computations in parallel. In modern-day programming, we&rsquo;re often talking about <em>both</em>. But to help us develop a stronger understanding, let&rsquo;s look at the two ideas one-at-a-time, and then bring it together.</p><h2 id=concurrency>Concurrency</h2><p>One of the earliest concurrency problems computer science dealt with was the efficient use of early computers. Consider a mainframe computer like the <a href=https://en.wikipedia.org/wiki/PDP-1 rel=external target=_blank>PDP-1</a>, once a staple of the university computer science department. In 1963, the base price of a PDP-1 was $120,000. Adjusted for inflation, this would be a price of a bit more than <em>one million dollars</em> in 2020! That&rsquo;s a pretty big investment! Any institution, be it a university, a corporation, or a government agency that spent that kind of money would want to use their new computer as efficiently as possible.</p><p>Consider when you are working on a math assignment and using a calculator. You probably read your problem carefully, write out an equation on paper, and then type a few calculations into your calculator, and copy the results to your paper. You might write a few lines as you progress through solving the problem, then punch a new calculation into your calculator. Between computations, your calculator is sitting idle - not doing anything. Mainframe computers worked much the same way - you loaded a program, it ran, and spat out results. Until you loaded a new program, the mainframe would be idle.</p><h3 id=batch-processing>Batch Processing</h3><p>An early solution was the use of <a href=https://en.wikipedia.org/wiki/Batch_processing rel=external target=_blank>batch processing</a>, where programs were prepared ahead of time on punch-card machines or the like, and turned over to an IT department team that would then feed these programs into the computer. In this way, the IT staff could keep the computer working as long as there was batched work to do. While this approach kept the computer busy, it was not ideal for the programmers. Consider the calculator example - it would be as if you had to write out your calculations and give them to another person to enter into the calculator. And they might not get you your results for days!</p><p>Can you imagine trying to write a program that way? In the early days that was <em>exactly</em> how CS students wrote programs - they would write an entire program on punch cards, turn it in to the computer staff to be batched, and get the results once it had been run. If they made a mistake, it would require another full round of typing cards, turning them in, and waiting for results!</p><p>Batch processing is still used for some kinds of systems - such as the generation of your DARS report at K-State, for sending email campaigns, and for running jobs on Beocat and other supercomputers. However, in mainframe operations it quickly was displaced by <em>time sharing</em>.</p><h3 id=time-sharing>Time Sharing</h3><p><a href=https://en.wikipedia.org/wiki/Time-sharing rel=external target=_blank>Time-sharing</a> is an approach that has much in common with its real-estate equivalent that shares its name. In real estate, a time-share is a vacation property that is owned by multiple people, who take turns using it. In a mainframe computer system, a time sharing approach likewise means that multiple people share a single computer. In this approach, terminals (a monitor and keyboard) are hooked up to the mainframe. But there is one important difference between time-sharing real estate and computers, which is why we can call this approach <em>concurrent</em>.</p><p>Let&rsquo;s return to the example of the calculator. In the moments between your typing an expression and reading the results, another student could type in their expression, and get their results. A time-sharing mainframe does exactly that - it take a few fractions of a second to advance each users&rsquo; program, switching between different users at lightning speed. Consider a newspaper where twenty people might we writing stories at a given moment - each terminal would capture key presses, and send them to the mainframe when it gave its attention, which would update the text editor, and send the resulting screen data back to the terminal. To the individual users, it would appear the computer was only working with them. But in actuality it was updating all twenty text editor program instances in real-time (at least to human perception).</p><p>Like batch processing, time-sharing is still used in computing today. If you&rsquo;ve used the thin clients in the DUE 1114 lab, these are the current-day equivalents of those early terminals. They&rsquo;re basically a video card, monitor, and input device that are hooked up to a server that runs multiple VMs (virtual machines), one for each client, and switches between them constantly updating each.</p><h3 id=multitasking>Multitasking</h3><p>The <a href=https://en.wikipedia.org/wiki/Microcomputer rel=external target=_blank>microcomputer revolution</a> did not do away with the concept. Rather, modern operating systems still use the basic concept of the approach, though in the context of a single computer it is known as <a href=https://en.wikipedia.org/wiki/Computer_multitasking rel=external target=_blank>multitasking</a>. When you write a paper now, your operating system is switching between processes in much the same way that time-sharing switched between users. It will switch to your text editor, processing your last keystroke and updating the text on screen. Then it will shift to your music player and stream the next few thousand bytes of the song you&rsquo;re listening to the sound card. Then it will switch to your email program which checks the email server and it will start to notify you that a new email has come in. Then it will switch back to your text editor.</p><p>The thin clients in DUE 1114 (as well as the remote desktops) are therefore both time-sharing between VMs and multitasking within VMs.</p><h2 id=parallel-processing>Parallel Processing</h2><p>The second approach to concurrency involves using <em>multiple</em> computers in parallel. K-State&rsquo;s <a href="https://support.beocat.ksu.edu/BeocatDocs/index.php?title=Main_Page" rel=external target=_blank>Beocat</a> is a good example of this - a supercomputer built of a lot of individual computers. But your laptop or desktop likely is as well; if you have a multi-core CPU, you actually have multiple processors built into your CPU, and each can run separate computational processes. This, it is entirely possible that as you are writing your term paper the text editor is running on one processor, your email application is using a second one, and your music is running on a third.</p><p>In fact, modern operating systems use both multitasking and parallel processing in tandem, spreading out the work to do across however many cores are available, and swapping between active processes to on those cores. Some programs also organize their own computation to run on multiple processors - your text editor might actually be handling your input on one core, running a spellcheck on a second, and a grammar check on a third.</p><p>Remember our earlier discussion about scaling web servers? This is <em>also</em> a parallel processing approach. Incoming HTTP requests are directed by a load balancer to a less-busy server, and that server formulates the response.</p><p><a href=#R-image-5049052fd58a3cc2b496769c3c758ef4 class=lightbox-link><img alt="Horizontal Scaling" class="border lazy lightbox noshadow figure-image" loading=lazy src=/cis526/images/3.2.1.png style=height:auto;width:auto></a>
<a href=javascript:history.back(); class=lightbox-back id=R-image-5049052fd58a3cc2b496769c3c758ef4><img alt="Horizontal Scaling" class="border lazy lightbox noshadow lightbox-image" loading=lazy src=/cis526/images/3.2.1.png></a></p><h3 id=multithreading>Multithreading</h3><p>Individual programs can <em>also</em> be written to execute on multiple cores. We typically call this approach <a href=https://en.wikipedia.org/wiki/Thread_(computing)#Multithreading rel=external target=_blank>Multithreading</a>, and the individually executing portions of the program code <em>threads</em>.</p><p>These aren&rsquo;t the only ways to approach concurrency, but they are ones we commonly see in practice. Before we turn our attention to how asynchronous processes fit in though, we&rsquo;ll want to discuss some of the challenges that concurrency brings.</p><footer class=footline></footer></article></div></main></div><script src=/cis526/js/clipboard.min.js?1739827139 defer></script><script src=/cis526/js/perfect-scrollbar.min.js?1739827139 defer></script><script src=/cis526/js/theme.js?1739827139 defer></script><script src=/cis526/js/embed-iframe.js?1739827139 defer></script></body></html>